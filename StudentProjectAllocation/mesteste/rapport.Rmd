---
title: | 
  | Analyse de deux algorithmes de tri par comparaison
  | ![](Images/logo_lamme.png){width=1in}  ![](Images/logo_UEVE.png){width=1.7in}
  |  M2 Data Science Algorithmique 
author:  "ATHOUMANI Ibroihima, AH-MOUK Laietitia, MBIBIK  Claude"
date: "jeudi 27 mars 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

\noindent\hrulefill


# Description du probl√®me et objectif

Nous √©tudions dans ce document le probl√®me tr√®s classique du tri des √©l√©ments d'un vecteur. Ce probl√®me consiste √† trier par ordre croissant les √©l√©ments d'un vecteur initialement non-tri√©. 

Il est int√©ressant de remarquer que de nombreuses m√©thodes algorithmiques r√©pondent √† ce probl√®me. Elles se distinguent par leur temps d'ex√©cution et par la m√©moire n√©cessaire √† r√©soudre la t√¢che. La question centrale est ici celle du temps d'ex√©cution.

[La page wikip√©dia du tri](https://fr.wikipedia.org/wiki/Algorithme_de_tri) rassemble de nombreux algorithmes de tri avec leurs avantages et inconv√©nients respectifs. La complexit√© du probl√®me de tri (par comparaison) est de $O(n \log n)$ pour un vecteur de longueur $n$. Cela signifie que, th√©oriquement, aucun algorithme ne pourra jamais √™tre plus rapide que cette borne asymptotique. Le *radix sort* et quelques autres algorithmes sont en temps $O(n)$ mais demandent des hypoth√®ses suppl√©mentaires sur les donn√©es (ce n'est plus un tri par comparaison).

Dans ce document, nous concentrons notre attention sur deux algorithmes de tri:

1) le tri par insertion, de complexit√© **$O(n^2)$**

2) le tri par tas (*heap sort*), de complexit√© **$O(n \log(n))$**. Des d√©tails sur le [tri par tas](https://en.wikipedia.org/wiki/Heapsort) sont donn√©s dans le lien, en particulier les animations donnent une bonne id√©e du fonctionnement d'un tas.


Nous avons donc ici deux m√©thodes l'une na√Øve, l'autre plus √©volu√©e. Nos objectifs sont alors:

a) d'impl√©menter ces algorithmes en R et en C++ et √©valuer le gain de temps;

b) de confirmer les complexit√©s th√©oriques trouv√©es sur le papier (ce n'est pas fait dans ce document mais a √©t√© fait dans le cours) par des simulations intensives.

___ 

√Ä noter que le (b) se termine toujours par l'√©valuation d'une pente sur une r√©gression lin√©aire en √©chelle log-log. Cela donne une √©valuation de la valeur $x$ dans la complexit√© de type $O(n^x)$ ou $O(n^x \log^y(n))$.

Nous allons ajouter une √©tape en plus. En effet, l'√©valuation de la complexit√© se fait sur des donn√©es simul√©es, issues d'une certaine distribution de probabilit√©. Nous souhaitons √©tudier le temps d'ex√©cution dans un cas plus favorable √† l'algorithme d'insertion.

___ 

# Un premier exemple

Le package se t√©l√©charge ainsi :

```{r, eval=FALSE}
devtools::install_github("vrunge/M2algorithmique")
```

et ses fonctions sont rendues disponibles sur Rstudio ainsi :

```{r}
library(StudentProjectAllocation)
```

On simule un petit exemple d'un vecteur `v` de taille `100`

```{r}
n <- 100 #data size 
generate_matrix <- function(n) {
  matrix(apply(matrix(1:n, n, n, byrow = TRUE), 1, sample), 
         nrow = n, byrow = TRUE)} #generate random cost matrix
cost_matrix<-generate_matrix(n)
```

On teste les 4 algorithmes impl√©ment√©s avec des noms explicites : 

- ` hungarian_algorithm` 
- `genetic_algorithm_assignment` 
- `hungarian_algorithm_cpp` 
- `genetic_algorithm_cpp` 

Cela donne :

```{r}
hungarian_algorithm(cost_matrix)
genetic_algorithm_assignment(cost_matrix)
hungarian_algorithm_cpp(cost_matrix)
genetic_algorithm_cpp(cost_matrix)
```


___ 

# Comparaison R avec C++

On va faire des comparaisons pour les deux types d'algorithme en R et C++ pour quantifier leur diff√©rence de performance.

La fonction `one.simu.time` retourne le temps recherch√©, et `one.simu` sera utilis√© par `microbenchmark`

```{r}
one.simu <- function(n, type = "random", func = "hungarian_algorithm")
{
  if(type == "random"){
    v <- generate_matrix(n)
  } else {
    v <- generate_matrix(n) # worst case scenario
  }
  if(func == "hungarian_algorithm"){t <- system.time(hungarian_algorithm(v))[[1]]}
  if(func == "genetic_algorithm_assignment"){t <- system.time(genetic_algorithm_assignment(v))[[1]]} 
  if(func == "hungarian_algorithm_cpp"){t <- system.time(hungarian_algorithm_cpp(v))[[1]]}
  if(func == "genetic_algorithm_cpp"){t <- system.time(genetic_algorithm_cpp(v))[[1]]}
  return(t)
}
```

## Un essai

Sur un exemple, on obtient :

```{r}
n <- 100
one.simu(n, func = "hungarian_algorithm")
one.simu(n, func = "genetic_algorithm_assignment")
one.simu(n, func = "hungarian_algorithm_cpp")
one.simu(n, func = "genetic_algorithm_cpp")
```


## Simulations avec r√©p√©titions

On reproduit ces comparaisons de mani√®re plus robuste:

```{r first simu}
nbSimus <- 10
time1 <- 0
time2 <- 0
time3 <- 0
time4 <- 0
for(i in 1:nbSimus){time1 <- time1 + one.simu(n, func = "hungarian_algorithm")}
for(i in 1:nbSimus){time2 <- time2 + one.simu(n, func = "genetic_algorithm_assignment")}
for(i in 1:nbSimus){time3 <- time3 + one.simu(n, func = "hungarian_algorithm_cpp")}
for(i in 1:nbSimus){time4 <- time4 + one.simu(n, func = "genetic_algorithm_cpp")}

```

gain R -> Rcpp

```{r}
time1/time3
time2/time4
```

gain hungarian -> genetic

```{r}

time1/time2
time3/time4
```

max gain

```{r}

time1/time4
```

On recommence avec `n = 20000` seulement pour le gain avec C++ pour le tas

```{r second simu}

```


**Conclusion:**

- pour une taille de `10000` la gain avec C++ atteint un facteur 500 entre le tas C++ et le tas R. Ce gain semble augmenter avec la taille. 

- Sans surprise, le tri par tas est plus rapide que le tri par insertion.

## Simulations avec `microbenchmark`

Vous avez besoin des packages `microbenchmark` et `ggplot2` pour ex√©cuter les simulations et afficher les r√©sultats (sous forme de diagrammes en violon). Nous comparons `insertion_sort_Rcpp` avec `heap_sort_Rcpp` pour des tailles de donn√©es `n = 1000` et `n = 10000`.

```{r}
library(microbenchmark)
library(ggplot2)
```

```{r benchmark, echo = FALSE, warning=FALSE, message=FALSE}
n <- 100
res <- microbenchmark(
  one.simu(n, func = "hungarian_algorithm_cpp"), 
  one.simu(n, func = "genetic_algorithm_cpp"), 
  times = 50
)
autoplot(res)
res
```

Genetic algorithm complexity
```{r, echo = FALSE, warning=FALSE, message=FALSE}

nbSimus <- 10
vector_n <- seq(from = 50, to = 500, length.out = nbSimus)
nbRep <- 10
res_Genetic <- data.frame(matrix(0, nbSimus, nbRep + 1))
colnames(res_Genetic) <- c("n", paste0("Rep",1:nbRep))

j <- 1
for(i in vector_n)
{
  res_Genetic[j,] <- c(i, replicate(nbRep, one.simu(i, func = "genetic_algorithm_cpp")))  
  print(j)
  j <- j + 1
}

res <- rowMeans(res_Genetic[,-1])
plot(vector_n, res, xlab = "matrix size (n x n)", ylab = "time in seconds")


```
```{r}
# Hungarian algorithm complexity
nbSimus <- 40
vector_n <- seq(from = 1000, to = 10000, length.out = nbSimus)  # smaller range due to O(n≥)
nbRep <- 10
res_Hungarian <- data.frame(matrix(0, nbSimus, nbRep + 1))
colnames(res_Hungarian) <- c("n", paste0("Rep",1:nbRep))

j <- 1
for(i in vector_n)
{
  res_Hungarian[j,] <- c(i, replicate(nbRep, one.simu(i, func = "hungarian_algorithm_cpp")))  
  print(j)
  j <- j + 1
}

res <- rowMeans(res_Hungarian[,-1])
plot(log(vector_n), log(res), xlab = "matrix size (n x n)", ylab = "time in seconds")
#lm(log(res) ~ log(vector_n))  # to estimate complexity
```


___ 


